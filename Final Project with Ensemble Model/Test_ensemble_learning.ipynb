{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Manisha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Manisha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Manisha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Manisha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Manisha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Manisha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Manisha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Manisha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Manisha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Manisha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Manisha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Manisha\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#DL Model\n",
    "import os, fnmatch\n",
    "import sys\n",
    "import librosa\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "#ML Model\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "\n",
    "# import cleaning\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path, offset):\n",
    "\ty, sr = librosa.load(audio_path, offset=offset, duration=3)\n",
    "\tS = librosa.feature.melspectrogram(\n",
    "\ty, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n",
    "\tmfccs = librosa.feature.mfcc(S=librosa.power_to_db(S), n_mfcc=40)\n",
    "\t# mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "\treturn mfccs\n",
    "\n",
    "def most_freq_dl(list):\n",
    "    # print(\"Ok1\")\n",
    "    return np.bincount(list).argmax()\n",
    "            \n",
    "MAX_SOUND_CLIP_DURATION=12 #sec  \n",
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+0.0001)\n",
    "    return data-0.5\n",
    "\n",
    "# get audio data without padding highest qualify audio\n",
    "def load_file_data_without_change(folder,file_names, duration=3, sr=16000):\n",
    "    input_length=sr*duration\n",
    "    # function to load files and extract features\n",
    "    # file_names = glob.glob(os.path.join(folder, '*.wav'))\n",
    "    data = []\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            sound_file=folder+file_name\n",
    "            print (\"load file \",sound_file)\n",
    "            # use kaiser_fast technique for faster extraction\n",
    "            X, sr = librosa.load( sound_file,res_type='kaiser_fast') \n",
    "            dur = librosa.get_duration(y=X, sr=sr)\n",
    "            # extract normalized mfcc feature from data\n",
    "            mfccs_ml = np.mean(librosa.feature.mfcc(y=X, sr=sr, n_mfcc=40).T,axis=0) \n",
    "        except Exception as e:\n",
    "            print(\"Error encountered while parsing file: \", file_name)\n",
    "        feature = np.array(mfccs_ml).reshape([-1,1])\n",
    "        data.append(feature)\n",
    "    return data\n",
    "\n",
    "\n",
    "# get audio data with a fix padding may also chop off some file\n",
    "def load_file_data (folder,file_names, duration=12, sr=16000):\n",
    "    input_length=sr*duration\n",
    "    # function to load files and extract features\n",
    "    # file_names = glob.glob(os.path.join(folder, '*.wav'))\n",
    "    data = []\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            sound_file=folder+file_name\n",
    "            print (\"load file \",sound_file)\n",
    "            # use kaiser_fast technique for faster extraction\n",
    "            X, sr = librosa.load( sound_file, sr=sr, duration=duration,res_type='kaiser_fast') \n",
    "            dur = librosa.get_duration(y=X, sr=sr)\n",
    "            # pad audio file same duration\n",
    "            if (round(dur) < duration):\n",
    "                print (\"fixing audio lenght :\", file_name)\n",
    "                y = librosa.util.fix_length(X, input_length)                \n",
    "            #normalized raw audio \n",
    "            # y = audio_norm(y)            \n",
    "            # extract normalized mfcc feature from data\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sr, n_mfcc=40).T,axis=0)             \n",
    "        except Exception as e:\n",
    "            print(\"Error encountered while parsing file: \", file_name)        \n",
    "        feature = np.array(mfccs).reshape([-1,1])\n",
    "        data.append(feature)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file to test\n",
    "ml_upload_folder_path = 'C:/Users/Manisha/BE_Project/Physionet_Dataset/training/training-c/'\n",
    "classify_file = 'C:/Users/Manisha/BE_Project/Physionet_Dataset/training/training-c/c0022.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_test_dl = []\n",
    "x_test_dl.append(extract_features(classify_file, 0.5))\n",
    "x_test_dl = np.asarray(x_test_dl)\n",
    "# print(x_test_dl.shape[0])\n",
    "# print(x_test_dl.shape[1])\n",
    "# print(x_test_dl.shape[2])\n",
    "# print(x_test_dl.shape[3])\n",
    "x_test_dl = x_test_dl.reshape(x_test_dl.shape[0], x_test_dl.shape[1], x_test_dl.shape[2], 1)\n",
    "model = keras.models.load_model('heartbeat_classifier_categorical_crossentropy.h5')\n",
    "pred_class = model.predict_classes(x_test_dl, verbose=1)\n",
    "CNNprob = model.predict_proba(x_test_dl, verbose=1)\n",
    "# CNNprob = CNNprob[:,1:]\n",
    "# print(CNNprob)\n",
    "CNNpred = np.argmax(CNNprob, axis=1)\n",
    "CNNpred = CNNpred + 1\n",
    "# print(CNNpred)\n",
    "print(type(pred_class))\n",
    "scores =[]\n",
    "scores = [accuracy_score(CNNpred,pred_class)]\n",
    "\n",
    "# print(accuracy_score(CNNpred,[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4710030680240553"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_dl[0][39][129][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load file  C:/Users/Manisha/BE_Project/Physionet_Dataset/training/training-c/c0022.wav\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "test_sounds = load_file_data(folder=ml_upload_folder_path,file_names=['c0022.wav'], duration=MAX_SOUND_CLIP_DURATION)\n",
    "test_labels = [-1 for items in test_sounds]\n",
    "testing_data_rf = np.squeeze(test_sounds)\n",
    "# print(testing_data_rf)\n",
    "testing_data_rf = testing_data_rf.reshape(1, -1)\n",
    "loaded_model = pickle.load(open('ml_classifier_random_forest.pkl', 'rb'))\n",
    "prediction_rf = loaded_model.predict(testing_data_rf)\n",
    "KNNProb = loaded_model.predict_proba(testing_data_rf)\n",
    "print(type(prediction_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(x_test_dl, testing_data_rf, dl_prediction_labels):\n",
    "#     # dl model\n",
    "#     pred_total = list()\n",
    "#     scores = []\n",
    "#     DLprob = []\n",
    "#     MLprob = []\n",
    "    \n",
    "#     DL1model = keras.models.load_model('heartbeat_classifier_binary_crossentropy.h5')\n",
    "#     DL2model = keras.models.load_model('heartbeat_classifier_categorical_crossentropy.h5')\n",
    "#         model = keras.models.load_model('CHF_Ensemble_Learners/model'+str(i)+'.h5')\n",
    "#         pred = model.predict_classes(x_test_dl)\n",
    "#         DLprob.append(model.predict_proba(x_test_dl))\n",
    "#         scores += [accuracy_score(pred,dl_prediction_labels)]\n",
    "#         pred_total.append(pred)\n",
    "     \n",
    "    \n",
    "#     loaded_model = pickle.load(open('model_rf', 'rb'))\n",
    "#     prediction_rf = loaded_model.predict(testing_data_rf)\n",
    "# #     probability_rf = loaded_model.predict_proba(testing_data_rf)\n",
    "#     scores += [accuracy_score(prediction_rf,dl_prediction_labels)] \n",
    "#     MLprob.append(loaded_model.predict_proba(testing_data_rf))\n",
    "    \n",
    "#     final_pred = []\n",
    "#     # CNNpred = pred_total[i]\n",
    "#     # MLPpred = pred_total[i+1]\n",
    "    \n",
    "# #     for i in range(len(prediction_rf)):\n",
    "# #         print(\"pred_total\", pred_total)\n",
    "# #         print(\"pred_total[i]\", pred_total[i])\n",
    "# #         print(\"pred_total[i + 1]\", pred_total[i + 1])\n",
    "# #         print(\"prediction_rf[i]\", prediction_rf[i])\n",
    "# #         if pred_total[i]==prediction_rf[i] and prediction_rf[i]==pred_total[i+1]:\n",
    "# #             print(\"OK1\")\n",
    "# #             final_pred += [pred_total[i]]\n",
    "# #         elif pred_total[i]==prediction_rf[i] or prediction_rf[i]==pred_total[i + 1] or pred_total[i]==pred_total[i + 1]:\n",
    "# #             print(\"OK2\")\n",
    "# #             if pred_total[i]==prediction_rf[i] or pred_total[i]==pred_total[i + 1]:\n",
    "# #                 final_pred += [pred_total[i]]\n",
    "# #             elif prediction_rf[i]==pred_total[i] or prediction_rf[i]==pred_total[i + 1]:\n",
    "# #                 final_pred += [prediction_rf[i]]\n",
    "# #             elif pred_total[i + 1]==pred_total[i] or pred_total[i + 1]==prediction_rf[i]:\n",
    "# #                 final_pred += [pred_total[i + 1]]\n",
    "# #             else:\n",
    "# #                 print('bug')\n",
    "# #         else:\n",
    "# #             print(\"OKK\")\n",
    "# # #             prob = DLprob[i] + DLprob[i + 1] + MLprob[i]\n",
    "# # #             pred = np.argmax(prob)\n",
    "# # #             pred = pred+1\n",
    "# # #             final_pred += [pred]\n",
    "\n",
    "#     for i in range(len(prediction_rf)):\n",
    "#         if pred_total[i]==prediction_rf[i]:\n",
    "#             print(\"yes\")\n",
    "#         else:\n",
    "#             print(\"No\")\n",
    "        \n",
    "\n",
    "\n",
    "#     final_pred = np.array(final_pred)\n",
    "#     print('final_pred', final_pred)\n",
    "#     print('labels: ',dl_prediction_labels)\n",
    "#     score = accuracy_score(final_pred,dl_prediction_labels)\n",
    "#     cm = confusion_matrix(final_pred,dl_prediction_labels)\n",
    "#     return score,cm,final_pred,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_list = [2,5,6,7,1,9,8]\n",
    "# print(my_list)\n",
    "# my_list.sort()\n",
    "# print(my_list[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl_prediction_labels = pred_class\n",
    "# acc_score, cm, final_predict, scores = test(x_test_dl, testing_data_rf, dl_prediction_labels)\n",
    "\n",
    "# print(acc_score)\n",
    "# print(final_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_clf = VotingClassifier(estimators=[('RF', loaded_model), ('CNN', model)], voting='hard')\n",
    "# voting_clf.fit(X_train, y_train)\n",
    "# preds = voting_clf.predict(testing_data_rf)\n",
    "# acc = accuracy_score(dl_prediction_labels, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_el(x_test_dl, testing_data_rf, dl_prediction_labels):\n",
    "    \n",
    "#     KNNmodel = MLmodel\n",
    "#     MLPmodel = DL1model\n",
    "#     CNNmodel = DL2model\n",
    "    \n",
    "    #Load saved models and PCA transformations\n",
    "    MLmodel = pickle.load(open('ml_classifier_random_forest.pkl', 'rb'))\n",
    "    DL1model = keras.models.load_model('heartbeat_classifier_binary_crossentropy.h5')\n",
    "    DL2model = keras.models.load_model('heartbeat_classifier_categorical_crossentropy.h5')\n",
    "    \n",
    "    #Make predictions with test data\n",
    "#     scores = []\n",
    "   \n",
    "    DL1pred = DL1model.predict_classes(x_test_dl)\n",
    "    DL1prob = DL1model.predict_proba(x_test_dl)\n",
    "#     scores += [accuracy_score(DL1pred,dl_prediction_labels)]\n",
    "    DL2prob = DL2model.predict(x_test_dl)\n",
    "    DL2prob = DL2prob[:,1:]\n",
    "    DL2pred = np.argmax(DL2prob, axis=1)\n",
    "    DL2pred = DL2pred + 1\n",
    "#     scores += [accuracy_score(DL2pred,dl_prediction_labels)]\n",
    "    \n",
    "    MLpred = MLmodel.predict(testing_data_rf)\n",
    "    MLprob = MLmodel.predict_proba(testing_data_rf)\n",
    "#     scores += [accuracy_score(MLpred,dl_prediction_labels)]\n",
    "    \n",
    "    #Ensemble learning/voting system\n",
    "    final_pred = []\n",
    "    \n",
    "    for i in range(len(MLpred)):\n",
    "        print(\"DL2pred: \", DL2pred[i], \"DL1pred: \", DL1pred[i], \"MLpred: \", MLpred[i])\n",
    "        if MLpred[i]==2:\n",
    "            MLpred[i] = 0\n",
    "        if DL2pred[i]==MLpred[i] and MLpred[i]==DL1pred[i]:\n",
    "            final_pred += [DL2pred[i]]\n",
    "        elif DL2pred[i]==MLpred[i] or MLpred[i]==DL1pred[i] or DL2pred[i]==DL1pred[i]:\n",
    "            if DL2pred[i]==MLpred[i] or DL2pred[i]==DL1pred[i]:\n",
    "                final_pred += [DL2pred[i]]\n",
    "            elif MLpred[i]==DL2pred[i] or MLpred[i]==DL1pred[i]:\n",
    "                final_pred += [MLpred[i]]\n",
    "            elif DL1pred[i]==DL2pred[i] or DL1pred[i]==MLpred[i]:\n",
    "                final_pred += [DL1pred[i]]\n",
    "            else:\n",
    "                print('bug')\n",
    "        else:\n",
    "            print(\"DL2prob[i]: \", DL2prob[i], \"DL1prob[i]:\", DL1prob[i], \"MLprob[i]: \", MLprob[i])\n",
    "            DL1prob_max = DL1prob.max()\n",
    "            MLprob_max = MLprob.max()\n",
    "            prob = DL2prob[i] + DL1prob_max + MLprob_max\n",
    "            pred = np.argmax(prob)\n",
    "            pred = pred+1\n",
    "            final_pred += [pred]\n",
    "    \n",
    "    #Outputs\n",
    "    final_pred = np.array(final_pred)\n",
    "#     score = accuracy_score(final_pred,dl_prediction_labels)\n",
    "#     cm = confusion_matrix(final_pred,dl_prediction_labels)\n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL2pred:  1 DL1pred:  1 MLpred:  2\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "dl_prediction_labels = pred_class\n",
    "\n",
    "final_pred = test_el(x_test_dl, testing_data_rf, dl_prediction_labels)\n",
    "\n",
    "print(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
